{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Inicializando Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'user_id', 'age', 'isbn', 'rating',\n",
       "       'book_title', 'book_author', 'year_of_publication', 'publisher',\n",
       "       'img_l', 'Language', 'Category', 'city', 'state', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('exame_cmc13_dados_teste.csv', sep=';')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos campos que não são mencionados e que, provavelmente, se referem apenas a identificações internas dos livros: 'Unnamed: 0.1' e 'Unnamed: 0'. Vamos excluí-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar a exluir colunas inúteis para a análise. Em um primeiro momento, podemos excluir as colunas de identificação do usuário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos filtrar as localidades. Para simplificar a análise, contaremos que leitores de um mesmo país têm gostos semelhantes, excluindo a necessidade de identificadores de cidades e estados. Isso também é permitido pelo fato de haver uma variedade de países:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usa                      25623\n",
       "canada                    3096\n",
       "united kingdom             655\n",
       "australia                  434\n",
       "germany                    258\n",
       "                         ...  \n",
       "queensland, australia        1\n",
       "pakistan                     1\n",
       "england                      1\n",
       "kenya                        1\n",
       "burma                        1\n",
       "Name: country, Length: 116, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem 116 países no dataset. Excluindo colunas referentes a localidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['city', 'state'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise da linguagem dos livros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    21670\n",
       "9     11125\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que apenas duas classificações foram categorizadas: en (inglês) e 9 (provavelmente um placeholder ou erro de obtenção de dados). Como a análise desses dois classificadores não nos fornece tanta informação, é razoável excluir tal coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Language'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos excluir as colunas 'isbn' porque se refere a uma identificação do livro, redundante com o título, e 'img_l', pois, apesar de a capa certamente ser importante para a escolha de um livro, apenas o link da imagem não adiciona tanto à análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['isbn', 'img_l'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que as colunas de idade e ano de publicação estão sendo tratadas como floats. Convertendo ambas para int:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].astype(int)\n",
    "df['year_of_publication'] = df['year_of_publication'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entretanto, ainda devem existir colunas com valores nulos. Vamos contá-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31684 entries, 0 to 32794\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   age                  31684 non-null  int32 \n",
      " 1   rating               31684 non-null  int64 \n",
      " 2   book_title           31684 non-null  object\n",
      " 3   book_author          31684 non-null  object\n",
      " 4   year_of_publication  31684 non-null  int32 \n",
      " 5   publisher            31684 non-null  object\n",
      " 6   Category             31684 non-null  object\n",
      " 7   country              31684 non-null  object\n",
      "dtypes: int32(2), int64(1), object(5)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que apenas 31684 linhas de 'country' tem valores não nulos, contra 32795 das outras colunas. Como são apenas 1111 de quase 33000 dados, representando aproximadamente 3% do dataset, podemos excluí-los sem grande perda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  rating                                         book_title  \\\n",
      "0       35       3                                 The Hours: A Novel   \n",
      "1       34      10                  Seven Up (A Stephanie Plum Novel)   \n",
      "2       33      10                                The Handmaid's Tale   \n",
      "3       33       8                                       The Notebook   \n",
      "4       44       0                                When the Wind Blows   \n",
      "...    ...     ...                                                ...   \n",
      "32790   59       0                                    Four Blind Mice   \n",
      "32791   34       9                The Red Tent (Bestselling Backlist)   \n",
      "32792   25       0                                      The Rainmaker   \n",
      "32793   55       0  Morality for Beautiful Girls (No.1 Ladies Dete...   \n",
      "32794   34       0                                     ANGELA'S ASHES   \n",
      "\n",
      "                  book_author  year_of_publication                publisher  \\\n",
      "0          Michael Cunningham                 2002                  Picador   \n",
      "1             Janet Evanovich                 2002  St. Martin's Paperbacks   \n",
      "2             Margaret Atwood                 1989            Fawcett Books   \n",
      "3             Nicholas Sparks                 1998             Warner Books   \n",
      "4             James Patterson                 1999            Warner Vision   \n",
      "...                       ...                  ...                      ...   \n",
      "32790         James Patterson                 2002            Little, Brown   \n",
      "32791           Anita Diamant                 1998              Picador USA   \n",
      "32792            JOHN GRISHAM                 1996                     Dell   \n",
      "32793  Alexander McCall Smith                 2002                   Anchor   \n",
      "32794           Frank McCourt                 1996                 Scribner   \n",
      "\n",
      "                                                Category country  \n",
      "0                                            ['Fiction']     usa  \n",
      "1                                                      9     usa  \n",
      "2      ['British and Irish fiction (Fictional works b...     usa  \n",
      "3                                                      9     usa  \n",
      "4                                            ['Fiction']     usa  \n",
      "...                                                  ...     ...  \n",
      "32790                                                  9     usa  \n",
      "32791                                        ['Fiction']     usa  \n",
      "32792                                        ['Fiction']     usa  \n",
      "32793                                        ['Fiction']     usa  \n",
      "32794                      ['Biography & Autobiography']     usa  \n",
      "\n",
      "[31684 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do modelo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(['rating'], axis = 1)\n",
    "Y_train = df['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodificando as Strings para que o fit no modelo funcione (strings não têm valor de análise para o SKLearn, por isso precisam ser encodificadas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Category</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>730</td>\n",
       "      <td>292</td>\n",
       "      <td>2002</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>551</td>\n",
       "      <td>188</td>\n",
       "      <td>2002</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>721</td>\n",
       "      <td>272</td>\n",
       "      <td>1989</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>770</td>\n",
       "      <td>307</td>\n",
       "      <td>1998</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>913</td>\n",
       "      <td>181</td>\n",
       "      <td>1999</td>\n",
       "      <td>145</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32790</th>\n",
       "      <td>59</td>\n",
       "      <td>257</td>\n",
       "      <td>181</td>\n",
       "      <td>2002</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32791</th>\n",
       "      <td>34</td>\n",
       "      <td>798</td>\n",
       "      <td>22</td>\n",
       "      <td>1998</td>\n",
       "      <td>96</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32792</th>\n",
       "      <td>25</td>\n",
       "      <td>795</td>\n",
       "      <td>167</td>\n",
       "      <td>1996</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32793</th>\n",
       "      <td>55</td>\n",
       "      <td>418</td>\n",
       "      <td>13</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32794</th>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>131</td>\n",
       "      <td>1996</td>\n",
       "      <td>118</td>\n",
       "      <td>11</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32795 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  book_title  book_author  year_of_publication  publisher  Category  \\\n",
       "0       35         730          292                 2002         94        30   \n",
       "1       34         551          188                 2002        127         0   \n",
       "2       33         721          272                 1989         42        13   \n",
       "3       33         770          307                 1998        143         0   \n",
       "4       44         913          181                 1999        145        30   \n",
       "...    ...         ...          ...                  ...        ...       ...   \n",
       "32790   59         257          181                 2002         74         0   \n",
       "32791   34         798           22                 1998         96        30   \n",
       "32792   25         795          167                 1996         31        30   \n",
       "32793   55         418           13                 2002          5        30   \n",
       "32794   34          43          131                 1996        118        11   \n",
       "\n",
       "       country  \n",
       "0          111  \n",
       "1          111  \n",
       "2          111  \n",
       "3          111  \n",
       "4          111  \n",
       "...        ...  \n",
       "32790      111  \n",
       "32791      111  \n",
       "32792      111  \n",
       "32793      111  \n",
       "32794      111  \n",
       "\n",
       "[32795 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "for column_name in X_train.columns:\n",
    "    if X_train[column_name].dtype == object:\n",
    "        X_train[column_name] = le.fit_transform(X_train[column_name])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos treinar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = 50, random_state = 1, max_iter = 300).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('exame_cmc13_dados_teste.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o mesmo tratamento feito aos dados de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['Unnamed: 0.1', 'Unnamed: 0', 'user_id', 'city', 'state', 'Language', 'isbn', 'img_l'], axis=1)\n",
    "df_test['age'] = df_test['age'].astype(int)\n",
    "df_test['year_of_publication'] = df_test['year_of_publication'].astype(int)\n",
    "\n",
    "X_test = df_test.drop(['rating'], axis = 1)\n",
    "Y_test = df_test['rating']\n",
    "\n",
    "for column_name in X_test.columns:\n",
    "    if X_test[column_name].dtype == object:\n",
    "        X_test[column_name] = le.fit_transform(X_test[column_name])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando a eficácia do modelo projetado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.588992224424455"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar qual o número de camadas que otimiza a classificação. Para isso, façamos uma lista com as porcentagens de acerto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    clf = MLPClassifier(hidden_layer_sizes = i, random_state = 1, max_iter = 300).fit(X_train, Y_train)\n",
    "    score.append(clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de camadas que retorna a maior acurácia é 18 , com precisão 0.5898460131117549\n"
     ]
    }
   ],
   "source": [
    "index_max = max(range(len(score)), key=score.__getitem__)\n",
    "print('A quantidade de camadas que retorna a maior acurácia é', index_max+1,', com precisão', score[index_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, façamos o modelo com maior precisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5898460131117549"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = 18, random_state = 1, max_iter = 300).fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
